#!/usr/bin/env python3
"""
Local embedding generator script
Bu script CV verilerini okuyup embedding'leri hesaplar ve dosya olarak kaydeder.
Deploy sÄ±rasÄ±nda API limiti olmayacak Ã§Ã¼nkÃ¼ embedding'ler Ã¶nceden hesaplanmÄ±ÅŸ olacak.
"""

import json
import numpy as np
import pickle
import os
from pathlib import Path

try:
    import tomllib  # Python 3.11+
except ModuleNotFoundError:  # pragma: no cover - fallback for <3.11
    import tomli as tomllib  # type: ignore[import]


def _load_gemini_key():
    """
    Tries to find the Gemini API key from environment variables or
    .streamlit/secrets.toml so that embedding generation works outside Streamlit.
    """
    key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
    if key:
        return key.strip()

    secrets_path = Path(__file__).resolve().parent / ".streamlit" / "secrets.toml"
    if secrets_path.exists():
        try:
            with open(secrets_path, "rb") as f:
                secrets = tomllib.load(f)
            key = secrets.get("GEMINI_API_KEY") or secrets.get("GOOGLE_API_KEY")
            if key:
                return str(key).strip()
        except Exception as exc:  # pragma: no cover - strictly best-effort
            print(f"âš ï¸ secrets.toml okunurken hata: {exc}")
    return None


GEMINI_KEY = _load_gemini_key()
if not GEMINI_KEY:
    raise RuntimeError(
        "Gemini API anahtarÄ± bulunamadÄ±. LÃ¼tfen GOOGLE_API_KEY veya GEMINI_API_KEY "
        "ortam deÄŸiÅŸkenini ayarlayÄ±n ya da .streamlit/secrets.toml iÃ§inde tanÄ±mlayÄ±n."
    )

# google.generativeai kÃ¼tÃ¼phanesi embed_content Ã§aÄŸrÄ±larÄ±nda GOOGLE_API_KEY deÄŸiÅŸkenini arÄ±yor.
os.environ["GOOGLE_API_KEY"] = GEMINI_KEY
os.environ.setdefault("GEMINI_API_KEY", GEMINI_KEY)

from google.generativeai.embedding import embed_content

def build_chunks(cv_json):
    """CV verilerini chunk'lara bÃ¶ler"""
    chunks = []
    
    for section, content in cv_json.items():
        if section in ['name', 'title', 'location', 'email', 'phone']:
            # KiÅŸisel bilgileri tek chunk'ta birleÅŸtir
            if section == 'name':
                personal_info = f"KiÅŸisel Bilgiler: {content}"
                if 'title' in cv_json:
                    personal_info += f" - {cv_json['title']}"
                if 'location' in cv_json:
                    personal_info += f" - {cv_json['location']}"
                chunks.append(personal_info)
        elif section == 'profile':
            chunks.append(f"Profil: {content}")
        elif section == 'education':
            # EÄŸitim bilgilerini tek chunk'ta birleÅŸtir
            edu_text = "EÄŸitim: "
            for edu in content:
                edu_text += f"{edu['institution']} - {edu['degree']} ({edu['years']}); "
            chunks.append(edu_text.strip())
        elif section == 'experience':
            # Her deneyimi ayrÄ± chunk yap
            for exp in content:
                exp_text = f"Deneyim: {exp['title']} at {exp['company']} ({exp['duration']}) - {exp['description']}"
                chunks.append(exp_text)
        elif section == 'skills':
            # Yetenekleri kategorilere gÃ¶re grupla
            for category, skills in content.items():
                skills_text = f"Yetenekler - {category}: {', '.join(skills)}"
                chunks.append(skills_text)
        elif section == 'projects':
            # Her projeyi ayrÄ± chunk yap
            for project in content:
                if isinstance(project, dict):
                    proj_text = f"Proje: {project.get('name', '')} - {project.get('description', '')}"
                    chunks.append(proj_text)
        elif section == 'links':
            # Linkleri tek chunk'ta birleÅŸtir
            links_text = "Linkler: " + " | ".join([f"{k}: {v}" for k, v in content.items()])
            chunks.append(links_text)
        else:
            # DiÄŸer bÃ¶lÃ¼mler iÃ§in genel yaklaÅŸÄ±m
            if isinstance(content, (str, int, float)):
                chunks.append(f"{section}: {content}")
    
    return chunks

def generate_embeddings(chunks, api_key=None):
    """Chunk'lar iÃ§in embedding'leri hesapla"""
    print(f"ðŸ”„ {len(chunks)} chunk iÃ§in embedding hesaplanÄ±yor...")
    
    embeddings = []
    for i, chunk in enumerate(chunks):
        print(f"   ðŸ“ Chunk {i+1}/{len(chunks)}: {chunk[:50]}...")
        
        try:
            # Google API ile embedding hesapla
            result = embed_content(model="models/embedding-001", content=chunk)
            embedding = np.asarray(result["embedding"])
            embeddings.append(embedding)
            
            # Progress gÃ¶ster
            if (i + 1) % 5 == 0:
                print(f"   âœ… {i+1}/{len(chunks)} tamamlandÄ±")
                
        except Exception as e:
            print(f"   âŒ Hata (chunk {i+1}): {str(e)}")
            # SÄ±fÄ±r vektÃ¶r ekle (fallback)
            embeddings.append(np.zeros(768))
    
    print(f"âœ… TÃ¼m embedding'ler hesaplandÄ±!")
    return np.vstack(embeddings)

def save_embeddings_data(chunks, embeddings, cv_json, output_file="embeddings_data.pkl"):
    """Embedding verilerini dosyaya kaydet"""
    data = {
        'chunks': chunks,
        'embeddings': embeddings,
        'cv_json': cv_json,
        'alias': {
            "deneyim": "experience", "tecrÃ¼be": "experience",
            "eÄŸitim": "education",  "projeler": "projects",
            "Ã¶dÃ¼ller": "awards",    "yetenek": "skills",
        }
    }
    
    with open(output_file, 'wb') as f:
        pickle.dump(data, f)
    
    print(f"ðŸ’¾ Embedding verileri '{output_file}' dosyasÄ±na kaydedildi")
    print(f"   ðŸ“Š {len(chunks)} chunk, {embeddings.shape[0]}x{embeddings.shape[1]} embedding")

def main():
    """Ana fonksiyon"""
    print("ðŸš€ Local Embedding Generator")
    print("=" * 50)
    
    # CV dosyasÄ±nÄ± oku
    cv_file = "betÃ¼l-cv.json"
    if not os.path.exists(cv_file):
        print(f"âŒ CV dosyasÄ± bulunamadÄ±: {cv_file}")
        return
    
    print(f"ðŸ“– CV dosyasÄ± okunuyor: {cv_file}")
    with open(cv_file, 'r', encoding='utf-8') as f:
        cv_json = json.load(f)
    
    # Chunk'larÄ± oluÅŸtur
    print("ðŸ”¨ Chunk'lar oluÅŸturuluyor...")
    chunks = build_chunks(cv_json)
    print(f"   ðŸ“ {len(chunks)} chunk oluÅŸturuldu")
    
    # Embedding'leri hesapla
    embeddings = generate_embeddings(chunks)
    
    # Dosyaya kaydet
    save_embeddings_data(chunks, embeddings, cv_json)
    
    print("\nðŸŽ‰ TamamlandÄ±!")
    print("ðŸ“ Åžimdi bu dosyalarÄ± Streamlit Cloud'a upload edebilirsiniz:")
    print("   - embeddings_data.pkl")
    print("   - betÃ¼l-cv.json")

if __name__ == "__main__":
    main()
